1	import numpy as np
2	import keras
3	from keras import layers
4	import tensorflow_datasets as tfds
5	import matplotlib.pyplot as plt


1 tfds.disable_progress_bar()
  2
3	train_ds, validation_ds, test_ds = tfds.load(
4	"cats_vs_dogs",
5	# Reserve 10% for validation and 10% for test
6	split=["train[:40%]", "train[40%:50%]", "train[50%:60%]"],
7	as_supervised=True,  # Include labels
8	)
  9
10	print(f"Number of training samples: {train_ds.cardinality()}")
11	print(f"Number of validation samples: {validation_ds.cardinality()}")
12	print(f"Number of test samples: {test_ds.cardinality()}")


1	plt.figure(figsize=(10, 10))
2	for i, (image, label) in enumerate(train_ds.take(9)):
3	ax = plt.subplot(3, 3, i + 1)
4	plt.imshow(image)
5	plt.title(int(label))


resize_fn = keras.layers.Resizing(150, 150)
  2
3	train_ds = train_ds.map(lambda x, y: (resize_fn(x), y))
4	validation_ds = validation_ds.map(lambda x, y: (resize_fn(x), y))
5	test_ds = test_ds.map(lambda x, y: (resize_fn(x), y))
1	augmentation_layers = [
2	layers.RandomFlip("horizontal"),
3	layers.RandomRotation(0.1),
4	]
  5
  6
7	def data_augmentation(x):
8	for layer in augmentation_layers:
9	x = layer(x)
10	return x
 11
 12
 13 train_ds = train_ds.map(lambda x, y: (data_augmentation(x), y))
  1 from tensorflow import data as tf_data
  2
  3 batch_size = 64
  4
5	train_ds = train_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()
6	validation_ds = validation_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()
7	test_ds = test_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()
1	for images, labels in train_ds.take(1):
2	plt.figure(figsize=(10, 10))   3    first_image = images[0]   4    for i in range(9):
5	ax = plt.subplot(3, 3, i + 1)
6	augmented_image = data_augmentation(np.expand_dims(first_image, 0))
7	plt.imshow(np.array(augmented_image[0]).astype("int32"))
8	plt.title(int(labels[0]))
1	base_model = keras.applications.Xception(
2	weights="imagenet",  # Load weights pre-trained on ImageNet.
3	input_shape=(150, 150, 3),
4	include_top=False,
5	)  # Do not include the ImageNet classifier at the top.
  6
7	# Freeze the base_model
8	base_model.trainable = False
  9
10	# Create new model on top
11	inputs = keras.Input(shape=(150, 150, 3))
 12
13	# Pre-trained Xception weights requires that input be scaled
14	# from (0, 255) to a range of (-1., +1.), the rescaling layer
15	# outputs: `(inputs * scale) + offset`
16	scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)
17	x = scale_layer(inputs)
 18
 19 # The base model contains batchnorm layers. We want to keep them in inference mod  20 # when we unfreeze the base model for fine-tuning, so we make sure that the  21 # base_model is running in inference mode here.
22	x = base_model(x, training=False)
23	x = keras.layers.GlobalAveragePooling2D()(x)
24	x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout
25	outputs = keras.layers.Dense(1)(x)
26	model = keras.Model(inputs, outputs)
 27
28 model summary(show trainable True)


1	model.compile(
2	optimizer=keras.optimizers.Adam(),
3	loss=keras.losses.BinaryCrossentropy(from_logits=True),
4	metrics=[keras.metrics.BinaryAccuracy()],
5	)
  6
7	epochs = 2
8	print("Fitting the top layer of the model")
9	model.fit(train_ds, epochs=epochs, validation_data=validation_ds)


Unfreeze the base_model. Note that it keeps running in inference mode   2 # since we passed `training=False` when calling it. This means that
  3 # the batchnorm layers will not update their batch statistics.   4 # This prevents the batchnorm layers from undoing all the training   5 # we've done so far.
6	base_model.trainable = True
7	model.summary(show_trainable=True)
  8
9	model.compile(
10	optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate
11	loss=keras.losses.BinaryCrossentropy(from_logits=True),
12	metrics=[keras.metrics.BinaryAccuracy()],
13	)
 14
15	epochs = 1
16	print("Fitting the end-to-end model")
17	model.fit(train_ds, epochs=epochs, validation_data=validation_ds)


1	print("Test dataset evaluation")
2	model.evaluate(test_ds)
